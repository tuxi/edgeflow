package kafka

import (
	"context"
	"github.com/segmentio/kafka-go"
	"log"
	"time"
)

// ConsumerService å®šä¹‰äº†æ¶ˆè´¹ Kafka æ¶ˆæ¯çš„é€šç”¨æ¥å£
type ConsumerService interface {
	// Consume å¯åŠ¨ä¸€ä¸ªåç¨‹æ¶ˆè´¹æŒ‡å®šä¸»é¢˜ï¼Œå°†æ¶ˆæ¯å‘é€åˆ°è¿”å›çš„é€šé“
	Consume(ctx context.Context, topic string, groupID string) (<-chan kafka.Message, error)
	Close()
}

type kafkaConsumer struct {
	brokerURL string
	// å¯ä»¥æ·»åŠ  map æ¥ç®¡ç†å¤šä¸ª Reader
}

func NewKafkaConsumer(brokerURL string) ConsumerService {
	return &kafkaConsumer{
		brokerURL: brokerURL,
	}
}

// Consume æ–¹æ³•çš„æ ¸å¿ƒé€»è¾‘
func (c *kafkaConsumer) Consume(ctx context.Context, topic string, groupID string) (<-chan kafka.Message, error) {
	// 1. åˆ›å»º kafka.Reader
	r := kafka.NewReader(kafka.ReaderConfig{
		Brokers:  []string{c.brokerURL},
		Topic:    topic,
		GroupID:  groupID, // ä¸åŒçš„ Gateway ä½¿ç”¨ä¸åŒçš„ GroupID
		MinBytes: 10e3,    // 10KB
		MaxBytes: 10e6,    // 10MB
		// ä»æœ€æ–°çš„ offset å¼€å§‹æ¶ˆè´¹ (é€šå¸¸å¯¹äºå®æ—¶æ¨é€æ˜¯æœ€ä½³é€‰æ‹©)
		StartOffset:    kafka.LastOffset,
		CommitInterval: time.Second, // å¯åŠ¨è‡ªåŠ¨æäº¤ï¼Œæ¯ç§’æäº¤ä¸€æ¬¡
		MaxAttempts:    3,
		// æ³¨æ„ï¼šå¦‚æœä½¿ç”¨è‡ªåŠ¨æäº¤ï¼Œå°±ä¸èƒ½åœ¨å¾ªç¯ä¸­æ‰‹åŠ¨è°ƒç”¨CommitMessages
	})
	// 2. åˆ›å»ºè¾“å‡ºé€šé“
	outputCh := make(chan kafka.Message, 1000) // ç¼“å†²åŒºç”¨äºå¹³æ»‘æµé‡

	// 3. å¯åŠ¨æ¶ˆè´¹åç¨‹
	go func() {
		defer close(outputCh)
		for {
			// é˜»å¡è¯»å–æ¶ˆæ¯
			m, err := r.FetchMessage(ctx)
			if err != nil {
				// å¦‚æœæ˜¯ Context è¢«å–æ¶ˆï¼ˆæœåŠ¡å…³é—­ï¼‰ï¼Œæ­£å¸¸é€€å‡º
				if ctx.Err() != nil {
					break
				}
				log.Printf("ERROR: Kafka read error on topic %s: %v", topic, err)
				time.Sleep(time.Second) // çŸ­æš‚ç­‰å¾…åé‡è¯•
				continue
			}

			// å°è¯•å°†æ¶ˆæ¯å‘é€åˆ°è¾“å‡ºé€šé“
			select {
			case outputCh <- m:
				// æˆåŠŸå‘é€ï¼Œä¾èµ– CommitInterval è‡ªåŠ¨æäº¤ Offset
				// ä¸éœ€è¦æ‰‹åŠ¨æäº¤
			case <-ctx.Done():
				// ä¸Šä¸‹æ–‡ç»“æŸï¼Œé€€å‡ºå¾ªç¯
				return // ä½¿ç”¨ return é€€å‡ºæ•´ä¸ªåç¨‹
			default:
				log.Printf("kafkaConsumer é˜Ÿåˆ—æ»¡åˆ™ä¸¢å¼ƒï¼šå¿«é€Ÿè·³è¿‡æ¶ˆæ¯")
				// ğŸš€ é˜Ÿåˆ—æ»¡åˆ™ä¸¢å¼ƒï¼šå¿«é€Ÿè·³è¿‡æ¶ˆæ¯ m
				// å¿…é¡»æ‰‹åŠ¨æäº¤ï¼Œå‘Šè¯‰ Kafka Broker è¿™ä¸ªæ¶ˆæ¯æˆ‘ä»¬å·²ç»å¤„ç†ï¼ˆå³ä¸¢å¼ƒï¼‰äº†ã€‚
				if err := r.CommitMessages(ctx, m); err != nil {
				}
				//ç§»é™¤ default: é€»è¾‘ï¼Œé¿å…åœ¨è‡ªåŠ¨æäº¤æ¨¡å¼ä¸‹æ‰‹åŠ¨å¤„ç† Offset
				//å¦‚æœç¼“å†²åŒºæ»¡äº†ï¼Œæœ€ç®€å•çš„æ–¹å¼æ˜¯é˜»å¡æˆ–ä»…ä¸¢å¼ƒä¸æäº¤ï¼Œè®©è‡ªåŠ¨æäº¤åœ¨ä¸‹ä¸€è½®å‘¨æœŸå¤„ç†ã€‚
			}

			// æ³¨æ„ï¼šè¿™é‡Œæ‰‹åŠ¨æäº¤ä¸¥é‡å½±å“å®¢æˆ·ç«¯æ¥æ”¶æ•°æ®çš„é¢‘ç‡ï¼Œå¯¼è‡´å»¶è¿Ÿï¼Œæˆ‘ä»¬è®¾ç½®CommitIntervalè‡ªåŠ¨æäº¤æ•°æ®
			// æäº¤ Offset (é‡è¦ï¼šç¡®ä¿æ¶ˆæ¯è¢«å¤„ç†åæ‰æäº¤)
			//if err := r.CommitMessages(ctx, m); err != nil {
			//	log.Printf("ERROR: Failed to commit offset: %v", err)
			//}
		}
		r.Close() // é€€å‡ºæ—¶å…³é—­ Reader
		log.Printf("Kafka Consumer for topic %s finished.", topic)
	}()

	return outputCh, nil
}

func (c *kafkaConsumer) Close() {
	// ç”±äº Reader åœ¨å…¶æ¶ˆè´¹åç¨‹é€€å‡ºæ—¶è‡ªåŠ¨å…³é—­ï¼Œ
	// è¿™é‡Œçš„ Close ä¸»è¦æ˜¯ç”¨äºæ¸…ç†ä»»ä½•å…¨å±€èµ„æºï¼Œç›®å‰å¯ä»¥ç•™ç©ºæˆ–ä»…è®°å½•æ—¥å¿—ã€‚
	log.Println("Kafka Consumer Service closing...")
}
